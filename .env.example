# Azure OpenAI
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# Azure AI Search
AZURE_SEARCH_ENDPOINT=https://your-instance.search.windows.net
AZURE_SEARCH_API_KEY=your-api-key
AZURE_SEARCH_INDEX_NAME=documents

# Database
DATABASE_URL=postgresql+asyncpg://raguser:ragpassword@localhost:5432/ragdb

# Redis
REDIS_URL=redis://localhost:6379

# Azure Blob Storage
AZURE_STORAGE_CONNECTION_STRING=your-connection-string
AZURE_STORAGE_CONTAINER_NAME=documents

# Security
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Application
DEBUG=True
LOG_LEVEL=INFO

# File Storage
FILE_STORAGE_PATH=./uploads

# Document Chunking Configuration
CHUNK_SIZE=1000                  # Default chunk size in characters (100-10000)
CHUNK_OVERLAP=200                # Overlap size between chunks (0-500)
CHUNKING_STRATEGY=japanese       # Chunking strategy: japanese or simple
ENABLE_AUTO_CHUNKING=true        # Enable automatic chunking on upload
MAX_CHUNKS_PER_DOCUMENT=1000     # Maximum chunks per document (10-10000)

# JWT Configuration
JWT_SECRET_KEY=your-secret-key-here-change-in-production-minimum-32-chars
JWT_ALGORITHM=HS256

# CORS Configuration (optional - uses defaults if not specified)
# CORS_ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:3001"]
# CORS_ALLOW_CREDENTIALS=true
# CORS_ALLOW_METHODS=["GET","POST","PUT","DELETE","OPTIONS"]
# CORS_ALLOW_HEADERS=["*"]

# Vector Search Configuration (pgvector)
VECTOR_DIMENSIONS=1536           # Vector dimensions (matches text-embedding-ada-002)
VECTOR_INDEX_TYPE=ivfflat        # Index type: ivfflat or hnsw
VECTOR_INDEX_LISTS=100           # Number of lists for ivfflat index
VECTOR_SEARCH_LIMIT=10           # Default search result limit

# Embedding Configuration
EMBEDDING_PROVIDER=mock          # Provider: openai, ollama, or mock
# OPENAI_API_KEY=your-openai-api-key
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=mxbai-embed-large
AUTO_GENERATE_EMBEDDINGS=true
EMBEDDING_BATCH_SIZE=100

# Vector Storage Configuration
ENABLE_VECTOR_STORAGE=true       # Enable vector storage in pgvector
VECTOR_STORAGE_BATCH_SIZE=100    # Batch size for vector storage operations
VECTOR_STORAGE_MAX_RETRIES=3     # Maximum retries for vector storage operations
VECTOR_STORAGE_RETRY_DELAY=1.0   # Initial retry delay in seconds (exponential backoff)